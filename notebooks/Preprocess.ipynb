{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea87cf1",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In this section, we will attempt to clean the following datasets:\n",
    "   - TLC Yellow Taxi Trips Record 2021/10-2022/04\n",
    "   - TLC Green Taxi Trips Record 2021/10-2022/04\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Note:</b>  There may be slight difference in the code and output between this notebook and the preprocessing.py. This notebook serves solely as an exploratory notebook to discover any parts in the data that need to be fixed or discarded. For the final preprocessing steps, please refer to the code in preprocessing.py or the output in EDA.ipynb.</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca877ef5",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cbaafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "import shapefile as shp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='pastel', color_codes=True)\n",
    "sns.mpl.rc('figure', figsize=(10,6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca5460",
   "metadata": {},
   "source": [
    "## Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a78569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting a Spark session\n",
    "spk = (\n",
    "    SparkSession.builder.appName('Playground')\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Read the parquet dataset\n",
    "green_df = spk.read.parquet('../data/raw/tlc_data/green')\n",
    "yellow_df = spk.read.parquet('../data/raw/tlc_data/yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3112191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances\n",
      "  Green cab    : 605648\n",
      "  Yellow cab   : 22821986\n",
      "Total instances: 23427634\n",
      "\n",
      "Number of features\n",
      "   Green cab    : 20\n",
      "   Yellow cab   : 19\n"
     ]
    }
   ],
   "source": [
    "total_instances = green_df.count() + yellow_df.count()\n",
    "print(f\"Number of instances\\n  Green cab    : {green_df.count()}\")\n",
    "print(f\"  Yellow cab   : {yellow_df.count()}\")\n",
    "print(f\"Total instances: {total_instances}\\n\")\n",
    "print(f\"Number of features\\n   Green cab    : {len(green_df.columns)}\")\n",
    "print(f\"   Yellow cab   : {len(yellow_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c69803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all variable names consistent\n",
    "column_name = {'VendorID': 'vendor_id', \n",
    "               'RatecodeID': 'rate_code_id', \n",
    "               'PULocationID': 'pu_location_id',\n",
    "               'DOLocationID': 'do_location_id'}\n",
    "\n",
    "for key, value in column_name.items():\n",
    "    green_df = green_df.withColumnRenamed(key,value)\n",
    "    yellow_df = yellow_df.withColumnRenamed(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c925757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green_df - yellow_df : {'lpep_pickup_datetime', 'trip_type', 'lpep_dropoff_datetime', 'ehail_fee'}\n",
      "yellow_df - green_df : {'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'airport_fee'}\n"
     ]
    }
   ],
   "source": [
    "# Check difference in features between the two data sets\n",
    "print(f\"green_df - yellow_df : {set(green_df.columns) - set(yellow_df.columns)}\")\n",
    "print(f\"yellow_df - green_df : {set(yellow_df.columns) - set(green_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff8f27",
   "metadata": {},
   "source": [
    "We can safely remove the `ehail_fee`, `airport_fees` and `trip_type` features because we would not have these features available when we are predicting hourly demand in a region so they are not useful in training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "894715d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the excess features\n",
    "green_df = green_df.drop(\"trip_type\", \"ehail_fee\")\n",
    "yellow_df = yellow_df.drop(\"airport_fee\")\n",
    "\n",
    "# Rename the datetime columns to match each other\n",
    "green_df = (green_df.withColumnRenamed('lpep_dropoff_datetime', 'tpep_dropoff_datetime')\n",
    "                    .withColumnRenamed('lpep_pickup_datetime', 'tpep_pickup_datetime'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c57245b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate both data sets\n",
    "df = yellow_df.union(green_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ba8ed",
   "metadata": {},
   "source": [
    "## Check for outliers in the data based on each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d388475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract trip duration in minutes\n",
    "df = df.withColumn('trip_duration_min',\n",
    "                   (func.col('tpep_dropoff_datetime').cast('long') - \n",
    "                    func.col('tpep_pickup_datetime').cast('long')) / 60)\n",
    "\n",
    "# Extract the date as a standalone feature\n",
    "df = df.withColumn(\"pickup_date\", \n",
    "                   func.to_date(func.col(\"tpep_pickup_datetime\")))\n",
    "\n",
    "df = df.withColumn(\"dropoff_date\",\n",
    "                   func.to_date(func.col(\"tpep_dropoff_datetime\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb67e2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpep_pickup_datetime:\n",
      "\tMax: 2028-12-07 15:48:15 \n",
      "\tMin: 2003-01-01 11:10:06\n",
      "\n",
      "tpep_dropoff_datetime:\n",
      "\tMax: 2028-12-07 16:29:13 \n",
      "\tMin: 2003-01-01 11:38:46 \n",
      "\n",
      "-RECORD 0------------------------------------\n",
      " summary               | count               \n",
      " passenger_count       | 22525003            \n",
      " trip_distance         | 23301155            \n",
      " trip_duration_min     | 23427634            \n",
      " fare_amount           | 23427634            \n",
      " extra                 | 23427634            \n",
      " mta_tax               | 23427634            \n",
      " tip_amount            | 23427634            \n",
      " tolls_amount          | 23427634            \n",
      " improvement_surcharge | 23427634            \n",
      " total_amount          | 23301155            \n",
      " congestion_surcharge  | 22525003            \n",
      "-RECORD 1------------------------------------\n",
      " summary               | mean                \n",
      " passenger_count       | 1.410832132728569   \n",
      " trip_distance         | 6.272660329069305   \n",
      " trip_duration_min     | 16.879362420892072  \n",
      " fare_amount           | 13.524061464779285  \n",
      " extra                 | 1.0163441912230753  \n",
      " mta_tax               | 0.5192007810093001  \n",
      " tip_amount            | 2.5185253346548833  \n",
      " tolls_amount          | 0.45628221697685745 \n",
      " improvement_surcharge | 0.8325981134272823  \n",
      " total_amount          | 20.005770661044508  \n",
      " congestion_surcharge  | 2.2687514869587364  \n",
      "-RECORD 2------------------------------------\n",
      " summary               | stddev              \n",
      " passenger_count       | 0.9954703175189176  \n",
      " trip_distance         | 654.299407274511    \n",
      " trip_duration_min     | 60.273978432717406  \n",
      " fare_amount           | 83.88815282395798   \n",
      " extra                 | 1.2402239193653783  \n",
      " mta_tax               | 0.5255663890097144  \n",
      " tip_amount            | 3.013032116442147   \n",
      " tolls_amount          | 1.872983373064709   \n",
      " improvement_surcharge | 4.2733705293456925  \n",
      " total_amount          | 84.66497654777666   \n",
      " congestion_surcharge  | 0.7614281051357565  \n",
      "-RECORD 3------------------------------------\n",
      " summary               | min                 \n",
      " passenger_count       | 0.0                 \n",
      " trip_distance         | 0.0                 \n",
      " trip_duration_min     | -104472.58333333333 \n",
      " fare_amount           | -2564.0             \n",
      " extra                 | -4.5                \n",
      " mta_tax               | -86.0               \n",
      " tip_amount            | -410.0              \n",
      " tolls_amount          | -88.75              \n",
      " improvement_surcharge | -250.3              \n",
      " total_amount          | -2567.8             \n",
      " congestion_surcharge  | -2.75               \n",
      "-RECORD 4------------------------------------\n",
      " summary               | max                 \n",
      " passenger_count       | Y                   \n",
      " trip_distance         | 351613.36           \n",
      " trip_duration_min     | 29336.516666666666  \n",
      " fare_amount           | 401092.32           \n",
      " extra                 | 33.5                \n",
      " mta_tax               | 450.0               \n",
      " tip_amount            | 999.99              \n",
      " tolls_amount          | 911.87              \n",
      " improvement_surcharge | 1532.85             \n",
      " total_amount          | 401095.62           \n",
      " congestion_surcharge  | 2.75                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check earliest and latest of datetime variables\n",
    "print(\"tpep_pickup_datetime:\\n\\tMax:\", df.agg({\"tpep_pickup_datetime\": \"max\"}).collect()[0][0],\n",
    "     \"\\n\\tMin:\", df.agg({\"tpep_pickup_datetime\": \"min\"}).collect()[0][0])\n",
    "\n",
    "print(\"\\ntpep_dropoff_datetime:\\n\\tMax:\", df.agg({\"tpep_dropoff_datetime\": \"max\"}).collect()[0][0],\n",
    "     \"\\n\\tMin:\", df.agg({\"tpep_dropoff_datetime\": \"min\"}).collect()[0][0], '\\n')\n",
    "\n",
    "# Check other variables\n",
    "df.select(['passenger_count',\n",
    "           'trip_distance',\n",
    "           'trip_duration_min',\n",
    "           'fare_amount',\n",
    "           'extra',\n",
    "           'mta_tax',\n",
    "           'tip_amount',\n",
    "           'tolls_amount',\n",
    "           'improvement_surcharge',\n",
    "           'total_amount',\n",
    "           'congestion_surcharge']).describe().show(vertical=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e383f",
   "metadata": {},
   "source": [
    "Despite having retrieved the data from 2021-10 to 2022-04, the dataset still contains records from previous years and future years (??). The numerical features such as `trip_distance`, `fare_amount`, `tolls_amount`, `total_amount`, `trip_duration` also contain unrealistic values which need to be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e51aa",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ad2e5",
   "metadata": {},
   "source": [
    "To clean the code, we need to first consider the minimum possible and logical value for each column:\n",
    "- `extra`, `mta_tax`, `tip_amount`, `tolls_amount`, `improvement_surcharge`, `congestion_surcharge` and `airport_fee` can take value greater or equal to 0.\n",
    "- `passenger_count` must take value greater or equal to 1.\n",
    "- We assume that the minimum `trip_distance` and `trip_duration_min` for a regular ride is atleast 0.5 miles and 1 min respectively.\n",
    "- Based on the TLC website, the initial fare of each ride is \\$2.5 so we assume that minimum `fare_amount` is \\$2.5\n",
    "- We also restrict `pu_location_id` to within the specified zones (1-263)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d89086b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter based on the minimum possible values for numerical features\n",
    "df1 = df.where((func.col('passenger_count') > 0) &\n",
    "               (func.col('trip_distance') > 0.5) &\n",
    "               (func.col('trip_duration_min') > 1) &\n",
    "               (func.col('fare_amount') >= 2.50) &\n",
    "               (func.col('extra') >= 0) &\n",
    "               (func.col('mta_tax') >= 0) &\n",
    "               (func.col('tip_amount') >= 0) &\n",
    "               (func.col('tolls_amount') >= 0) &\n",
    "               (func.col('improvement_surcharge') >= 0) &\n",
    "               (func.col('total_amount') >= 0) &\n",
    "               (func.col('congestion_surcharge') >= 0) &\n",
    "               (func.col('pu_location_id') >= 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22084931",
   "metadata": {},
   "source": [
    "Since the dataset is too large, it is not feasible to check the outlier individually for each numerical column. So instead, we looked at the 99.99th percentile of the data and decide if the value is logical and possible.\n",
    "\n",
    "We also capped the `trip_duration_min` to atmost 5 hours (300 mins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d4e6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the columns to cover 99.99 percentile of the data for numerical features\n",
    "df1 = df1.where((func.col('fare_amount') <= df1.selectExpr('percentile(fare_amount, 0.9999)').collect()[0][0]) &\n",
    "                (func.col('trip_distance') <= df1.selectExpr('percentile(trip_distance, 0.9999)').collect()[0][0]) &\n",
    "                (func.col('tip_amount') <= df1.selectExpr('percentile(tip_amount, 0.9999)').collect()[0][0]) &\n",
    "                (func.col('total_amount') <= df1.selectExpr('percentile(total_amount, 0.9999)').collect()[0][0]) &\n",
    "                (func.col('tolls_amount') <= df1.selectExpr('percentile(tolls_amount, 0.9999)').collect()[0][0]) &\n",
    "                (func.col('trip_duration_min') <= 300) &\n",
    "                (func.col('pu_location_id') <= 263))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fca21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the period to between 2021-10 to 2022-04\n",
    "df1 = df1.where((func.col(\"pickup_date\") >= '2021-10-01') & \n",
    "                (func.col(\"dropoff_date\") >= '2021-10-01') &\n",
    "                (func.col(\"pickup_date\") <= '2022-04-30') & \n",
    "                (func.col(\"dropoff_date\") <= '2022-04-30'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d8cc9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>passenger_count</th><th>trip_distance</th><th>trip_duration_min</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th></tr>\n",
       "<tr><td>count</td><td>20131927</td><td>20131927</td><td>20131927</td><td>20131927</td><td>20131927</td><td>20131927</td><td>20131927</td><td>20131927</td><td>20131927</td><td>20131927</td><td>20131927</td></tr>\n",
       "<tr><td>mean</td><td>1.4474582090427806</td><td>3.372818759970744</td><td>15.128057352218038</td><td>13.816403430730837</td><td>1.0308856847136383</td><td>0.4978774863429622</td><td>2.6037678300741995</td><td>0.4541050566115406</td><td>0.29998997117181014</td><td>20.448662433051897</td><td>2.3495472539712665</td></tr>\n",
       "<tr><td>stddev</td><td>0.9885175522956113</td><td>4.142501840354908</td><td>11.470636373695918</td><td>11.63274126021313</td><td>1.2378554933189074</td><td>0.0332379381415083</td><td>2.774715266330236</td><td>1.7920122765500728</td><td>0.001734518214881...</td><td>14.82007017174797</td><td>0.5945534599851244</td></tr>\n",
       "<tr><td>min</td><td>1.0</td><td>0.51</td><td>1.0166666666666666</td><td>2.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>0.0</td></tr>\n",
       "<tr><td>max</td><td>9.0</td><td>57.3</td><td>299.9166666666667</td><td>200.0</td><td>33.5</td><td>17.1</td><td>50.0</td><td>25.8</td><td>0.3</td><td>231.85</td><td>2.75</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+---------------------+------------------+--------------------+\n",
       "|summary|   passenger_count|    trip_distance| trip_duration_min|       fare_amount|             extra|           mta_tax|        tip_amount|      tolls_amount|improvement_surcharge|      total_amount|congestion_surcharge|\n",
       "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+---------------------+------------------+--------------------+\n",
       "|  count|          20131927|         20131927|          20131927|          20131927|          20131927|          20131927|          20131927|          20131927|             20131927|          20131927|            20131927|\n",
       "|   mean|1.4474582090427806|3.372818759970744|15.128057352218038|13.816403430730837|1.0308856847136383|0.4978774863429622|2.6037678300741995|0.4541050566115406|  0.29998997117181014|20.448662433051897|  2.3495472539712665|\n",
       "| stddev|0.9885175522956113|4.142501840354908|11.470636373695918| 11.63274126021313|1.2378554933189074|0.0332379381415083| 2.774715266330236|1.7920122765500728| 0.001734518214881...| 14.82007017174797|  0.5945534599851244|\n",
       "|    min|               1.0|             0.51|1.0166666666666666|               2.5|               0.0|               0.0|               0.0|               0.0|                  0.0|               3.0|                 0.0|\n",
       "|    max|               9.0|             57.3| 299.9166666666667|             200.0|              33.5|              17.1|              50.0|              25.8|                  0.3|            231.85|                2.75|\n",
       "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+---------------------+------------------+--------------------+"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the descriptive statistics of all numerical columns\n",
    "df1.select(['passenger_count',\n",
    "           'trip_distance',\n",
    "           'trip_duration_min',\n",
    "           'fare_amount',\n",
    "           'extra',\n",
    "           'mta_tax',\n",
    "           'tip_amount',\n",
    "           'tolls_amount',\n",
    "           'improvement_surcharge',\n",
    "           'total_amount',\n",
    "           'congestion_surcharge',\n",
    "           'pickup_date']).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "702b4a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_date: 2021-10-01 - 2022-04-30\n",
      "dropoff_date: 2021-10-01 - 2022-04-30\n"
     ]
    }
   ],
   "source": [
    "# Check period of data\n",
    "pu_earliest, pu_latest = df1.select(func.min(\"pickup_date\"), func.max(\"pickup_date\")).first()\n",
    "do_earliest, do_latest = df1.select(func.min(\"dropoff_date\"), func.max(\"dropoff_date\")).first()\n",
    "\n",
    "print(f\"pickup_date: {pu_earliest} - {pu_latest}\")\n",
    "print(f\"dropoff_date: {do_earliest} - {do_latest}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c738174",
   "metadata": {},
   "source": [
    "The dataset looks much cleaner now and easier to work with. In the following parts, we will begin feature engineering to facilitate our analysis later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a100bc36",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef271a",
   "metadata": {},
   "source": [
    "## Extract hourly pickup and dropoff demand in each location id\n",
    "\n",
    "We first create columns to record date and hour. Then we group by `pu_location_id`/`do_location_id`, `date` and `hour` before counting the number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "609be349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns for date and hour\n",
    "df1 = (df1\n",
    "  .withColumn(\"pickup_date\", func.col(\"tpep_pickup_datetime\").cast(\"date\"))\n",
    "  .withColumn(\"pickup_hour\", func.hour(func.col(\"tpep_pickup_datetime\")))\n",
    "  .withColumn(\"dropoff_date\", func.col(\"tpep_dropoff_datetime\").cast(\"date\"))\n",
    "  .withColumn(\"dropoff_hour\", func.hour(func.col(\"tpep_dropoff_datetime\")))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8151de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate and count number of hourly instances in each location id\n",
    "pickup_hourly_demand = df1.groupBy(\"pu_location_id\", \"pickup_date\", \"pickup_hour\").count()\n",
    "dropoff_hourly_demand = df1.groupBy(\"do_location_id\", \"dropoff_date\", \"dropoff_hour\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4a11bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate and count number of daily instances in each location id\n",
    "pickup_daily_demand = df1.groupBy(\"pu_location_id\", \"pickup_date\").count()\n",
    "dropoff_daily_demand = df1.groupBy(\"do_location_id\", \"dropoff_date\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e77770c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>pu_location_id</th><th>pickup_date</th><th>pickup_hour</th><th>count</th></tr>\n",
       "<tr><td>48.0</td><td>2022-03-02</td><td>22</td><td>208</td></tr>\n",
       "<tr><td>138.0</td><td>2022-03-06</td><td>23</td><td>244</td></tr>\n",
       "<tr><td>50.0</td><td>2022-03-07</td><td>13</td><td>43</td></tr>\n",
       "<tr><td>13.0</td><td>2022-03-11</td><td>11</td><td>35</td></tr>\n",
       "<tr><td>263.0</td><td>2022-03-13</td><td>7</td><td>36</td></tr>\n",
       "<tr><td>132.0</td><td>2022-03-29</td><td>4</td><td>37</td></tr>\n",
       "<tr><td>162.0</td><td>2022-03-01</td><td>7</td><td>139</td></tr>\n",
       "<tr><td>97.0</td><td>2022-03-01</td><td>7</td><td>1</td></tr>\n",
       "<tr><td>177.0</td><td>2022-03-01</td><td>8</td><td>1</td></tr>\n",
       "<tr><td>95.0</td><td>2022-03-01</td><td>10</td><td>1</td></tr>\n",
       "<tr><td>70.0</td><td>2022-03-01</td><td>16</td><td>16</td></tr>\n",
       "<tr><td>164.0</td><td>2022-03-01</td><td>18</td><td>208</td></tr>\n",
       "<tr><td>40.0</td><td>2022-03-01</td><td>19</td><td>3</td></tr>\n",
       "<tr><td>140.0</td><td>2022-03-01</td><td>23</td><td>23</td></tr>\n",
       "<tr><td>143.0</td><td>2022-03-02</td><td>2</td><td>3</td></tr>\n",
       "<tr><td>249.0</td><td>2022-03-02</td><td>6</td><td>28</td></tr>\n",
       "<tr><td>186.0</td><td>2022-03-02</td><td>8</td><td>245</td></tr>\n",
       "<tr><td>47.0</td><td>2022-03-02</td><td>8</td><td>2</td></tr>\n",
       "<tr><td>162.0</td><td>2022-03-02</td><td>11</td><td>178</td></tr>\n",
       "<tr><td>186.0</td><td>2022-03-02</td><td>12</td><td>187</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------+-----------+-----------+-----+\n",
       "|pu_location_id|pickup_date|pickup_hour|count|\n",
       "+--------------+-----------+-----------+-----+\n",
       "|          48.0| 2022-03-02|         22|  208|\n",
       "|         138.0| 2022-03-06|         23|  244|\n",
       "|          50.0| 2022-03-07|         13|   43|\n",
       "|          13.0| 2022-03-11|         11|   35|\n",
       "|         263.0| 2022-03-13|          7|   36|\n",
       "|         132.0| 2022-03-29|          4|   37|\n",
       "|         162.0| 2022-03-01|          7|  139|\n",
       "|          97.0| 2022-03-01|          7|    1|\n",
       "|         177.0| 2022-03-01|          8|    1|\n",
       "|          95.0| 2022-03-01|         10|    1|\n",
       "|          70.0| 2022-03-01|         16|   16|\n",
       "|         164.0| 2022-03-01|         18|  208|\n",
       "|          40.0| 2022-03-01|         19|    3|\n",
       "|         140.0| 2022-03-01|         23|   23|\n",
       "|         143.0| 2022-03-02|          2|    3|\n",
       "|         249.0| 2022-03-02|          6|   28|\n",
       "|         186.0| 2022-03-02|          8|  245|\n",
       "|          47.0| 2022-03-02|          8|    2|\n",
       "|         162.0| 2022-03-02|         11|  178|\n",
       "|         186.0| 2022-03-02|         12|  187|\n",
       "+--------------+-----------+-----------+-----+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickup_hourly_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a6d0b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>pu_location_id</th><th>count</th></tr>\n",
       "<tr><td>count</td><td>40666</td><td>40666</td></tr>\n",
       "<tr><td>mean</td><td>134.81751340185906</td><td>495.055500909851</td></tr>\n",
       "<tr><td>stddev</td><td>75.9882553142365</td><td>1027.335342503522</td></tr>\n",
       "<tr><td>min</td><td>1.0</td><td>1</td></tr>\n",
       "<tr><td>max</td><td>263.0</td><td>6907</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+------------------+-----------------+\n",
       "|summary|    pu_location_id|            count|\n",
       "+-------+------------------+-----------------+\n",
       "|  count|             40666|            40666|\n",
       "|   mean|134.81751340185906| 495.055500909851|\n",
       "| stddev|  75.9882553142365|1027.335342503522|\n",
       "|    min|               1.0|                1|\n",
       "|    max|             263.0|             6907|\n",
       "+-------+------------------+-----------------+"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickup_daily_demand.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb45d381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>do_location_id</th><th>count</th></tr>\n",
       "<tr><td>count</td><td>52317</td><td>52317</td></tr>\n",
       "<tr><td>mean</td><td>133.81677083930654</td><td>384.80660206051573</td></tr>\n",
       "<tr><td>stddev</td><td>76.92941804905843</td><td>800.8124201636705</td></tr>\n",
       "<tr><td>min</td><td>1.0</td><td>1</td></tr>\n",
       "<tr><td>max</td><td>265.0</td><td>5969</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+------------------+------------------+\n",
       "|summary|    do_location_id|             count|\n",
       "+-------+------------------+------------------+\n",
       "|  count|             52317|             52317|\n",
       "|   mean|133.81677083930654|384.80660206051573|\n",
       "| stddev| 76.92941804905843| 800.8124201636705|\n",
       "|    min|               1.0|                 1|\n",
       "|    max|             265.0|              5969|\n",
       "+-------+------------------+------------------+"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropoff_daily_demand.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6a79e",
   "metadata": {},
   "source": [
    "It appears that the average daily pickup demand is about 494 with maximum number of pickup per hour at 6907. However, since demand is strongly based on `LocationID` which explains the large standard deviation at 1023.1, we need to examine the demand statistics based on individual location to make a legitimate inference. This will be done in EDA.ipynb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
